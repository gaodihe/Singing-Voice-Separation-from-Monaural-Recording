{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.io.wavfile as wavfile\n",
    "from numpy.linalg import norm\n",
    "from numpy.linalg import svd \n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pcp_alm(X, maxiter=500, tol=1e-7):\n",
    "    \"\"\"Principal Component Pursuit\n",
    "    Finds the Principal Component Pursuit solution.\n",
    "    Solves the optimization problem::\n",
    "        (L^*,S^*) = argmin || L ||_* + gamma * || S ||_1\n",
    "                    (L,S)\n",
    "                    subject to    L + S = X\n",
    "    where || . ||_* is the nuclear norm.  Uses an augmented Lagrangian approach\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape [n_samples, n_features]\n",
    "        Data matrix.\n",
    "    maxiter : int, 500 by default\n",
    "        Maximum number of iterations to perform.\n",
    "    tol : float, 1e-7 by default - in the paper\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L : array of shape [n_samples, n_features]\n",
    "        The low rank component\n",
    "    S : array of shape [n_samples, n_features]\n",
    "        The sparse component\n",
    "    (u, sig, vt) : tuple of arrays\n",
    "        SVD of L.\n",
    "    n_iter : int\n",
    "        Number of iterations\n",
    "    Reference\n",
    "    ---------\n",
    "       Candes, Li, Ma, and Wright\n",
    "       Robust Principal Component Analysis?\n",
    "       Submitted for publication, December 2009.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def soft_threshold(v = 0, tau = 0):\n",
    "        '''\n",
    "        shrinkiage opterator S_tau[x]\n",
    "        '''\n",
    "        tmp = np.abs(v)\n",
    "        tmp = np.subtract(tmp, tau)\n",
    "        tmp = np.maximum(tmp, 0.0)\n",
    "        return np.multiply(np.sign(v), tmp)\n",
    "    \n",
    "    def svt(X, tau, k, svd_function, out=None):\n",
    "        def svd_reconstruct(u, sig, v, out=None, tmp_out=None):\n",
    "            tmp = np.multiply(u, sig, out=tmp_out)\n",
    "            return np.dot(tmp, v, out=out)\n",
    "\n",
    "        def truncate_top_k_svd(u, sig, v, k):\n",
    "            return u[:, :k], sig[:k], v[:k, :]\n",
    "\n",
    "        m, n = X.shape\n",
    "        \n",
    "        u, sig, v = svd_function(X, k)\n",
    "\n",
    "        sig = soft_threshold(sig, tau)\n",
    "        r = np.sum(sig > 0)\n",
    "        \n",
    "        u, sig, v = svd_function(X, r)\n",
    "        sig = soft_threshold(sig, tau)\n",
    "\n",
    "        if r > 0:\n",
    "            #print(\"Z= reconstructed\")\n",
    "            u, sig, v = truncate_top_k_svd(u, sig, v, r)\n",
    "            #print(\"reconstructed sig =\", sig)\n",
    "            Z = svd_reconstruct(u, sig, v, out=out)\n",
    "        else:\n",
    "            #print(\"Z= 0\")\n",
    "            out[:] = 0\n",
    "            Z = out\n",
    "            u, sig, v = np.empty((m, 0)), np.empty((0, 0)), np.empty((0, n))\n",
    "        return (Z, r, (u, sig, v))\n",
    "    \n",
    "    def svd_choice(n, d):\n",
    "        '''\n",
    "        choose svd depend on the size \n",
    "\n",
    "        return 'dense_top_k_svd/sparse_svds\n",
    "        '''\n",
    "    \n",
    "        ratio = float(d) / float(n)\n",
    "        vals = [(0, 0.02), (100, 0.06), (200, 0.26),\n",
    "                (300, 0.28), (400, 0.34), (500, 0.38)]\n",
    "\n",
    "        i = bisect.bisect_left([r[0] for r in vals], n)\n",
    "        choice = dense_top_k_svd if ratio > vals[i-1][1] else svds\n",
    "        return choice\n",
    "    \n",
    "    def dense_top_k_svd(A, k):\n",
    "        '''\n",
    "        A - matrix\n",
    "        k - Top K components\n",
    "        '''\n",
    "        u, sig, v = svd(A, full_matrices=0)\n",
    "        return u[:, :k], sig[:k], v[:k, :]\n",
    "    \n",
    "    n = X.shape\n",
    "    frob_norm = np.linalg.norm(X, 'fro')\n",
    "    two_norm = np.linalg.norm(X, 2)\n",
    "    one_norm = np.sum(np.abs(X))\n",
    "    inf_norm = np.max(np.abs(X))\n",
    "    \n",
    "    print(\"frob_norm\", frob_norm)\n",
    "    print(\"two_norm\", two_norm)\n",
    "    print(\"one_norm\", one_norm)\n",
    "    print(\"info_norm\", inf_norm)\n",
    "\n",
    "    mu_inv = 4 * one_norm / np.prod(n)\n",
    "    \n",
    "    gamma = 1/np.sqrt(np.max([X.shape[0], X.shape[1]]))\n",
    "    print(\"gamma\", gamma)\n",
    "    # Kicking\n",
    "    k = np.min([\n",
    "        np.floor(mu_inv / two_norm),\n",
    "        np.floor(gamma * mu_inv / inf_norm)\n",
    "    ])\n",
    "    Y = k * X\n",
    "    sv = 10\n",
    "\n",
    "    # Variable init\n",
    "    S = np.zeros(n)\n",
    "    \n",
    "    #print(\"k\",k)\n",
    "    #print(\"mu_inv\", mu_inv)\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        \n",
    "        # Shrink singular values\n",
    "        l= X - S + mu_inv*Y\n",
    "        svd_fun = svd_choice(np.min(l.shape), sv)\n",
    "        #print(svd_fun)\n",
    "        #print(\"sv\", sv)\n",
    "        L, r, (u, sig, v) = svt(l, mu_inv, sv, svd_function = svd_fun)\n",
    "        #print(\"non-zero sigular value\", r)          \n",
    "        if r < sv:\n",
    "            sv = np.min([r + 1, np.min(n)])\n",
    "        else:\n",
    "            sv = np.min([r +  int(np.round(0.05 * np.min(n))), np.min(n)])\n",
    "        \n",
    "        # Shrink entries\n",
    "        s = X - L + mu_inv*Y\n",
    "        S = soft_threshold(s, gamma * mu_inv)\n",
    "    \n",
    "        # Check convergence\n",
    "        R= X - L - S\n",
    "        stopCriterion = np.linalg.norm(R, 'fro') / frob_norm\n",
    "        #print(\"stopCriterion\", stopCriterion)\n",
    "        if stopCriterion < tol:\n",
    "            break\n",
    "\n",
    "        # Update dual variable\n",
    "        Y += 1/mu_inv *(X - L - S) \n",
    "\n",
    "    return L, S, (u, sig, v), i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, filename, sampling_rate=16000, mix=False):\n",
    "    '''\n",
    "    Function to load the '.wav' data\n",
    "    @param path: str, where data is read from\n",
    "    @param filename: str, file name, should end in '.wav'\n",
    "    @param sampling rate: int, default is 16000. 22,050 is also a common value but not applicable to this project\n",
    "    @param mix: bool, if True, then the left sound track and right sound track are mixed to a mono track signal\n",
    "    '''\n",
    "    song = librosa.load(path + filename, sr = sampling_rate, mono=mix)[0]\n",
    "    if mix:\n",
    "        return song[0]\n",
    "    else:\n",
    "        return song[0], song[1]\n",
    "    \n",
    "def save_data(path, filename, data, sampling_rate=16000):\n",
    "    wavfile.write(path+filename, rate=sampling_rate, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frob_norm 1899.79\n",
      "two_norm 832.697\n",
      "one_norm 262467.0\n",
      "info_norm 126.659\n",
      "gamma 0.0312347523777\n",
      "frob_norm 1900.19\n",
      "two_norm 767.001\n",
      "one_norm 176796.0\n",
      "info_norm 140.115\n",
      "gamma 0.0312347523777\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "data_path = '../data/MIR-1K_for_MIREX/Wavfile/'\n",
    "output_path = '../output/'\n",
    "filename = 'abjones_1_01.wav'\n",
    "music, voice = load_data(data_path, filename)\n",
    "\n",
    "# Short-Time Fourier Transformation\n",
    "music_stft = librosa.stft(music)\n",
    "voice_stft = librosa.stft(voice)\n",
    "\n",
    "# Apply the rPCA\n",
    "L_music, S_music, r_music, n_iter_music = pcp_alm(music_stft)\n",
    "L_voice, S_voice, r_voice, n_iter_voice = pcp_alm(voice_stft)\n",
    "\n",
    "# Inverse Short-Time Fourier Transformation\n",
    "L_music_istft = librosa.istft(L_music)\n",
    "S_music_istft = librosa.istft(S_music)\n",
    "L_voice_istft = librosa.istft(L_voice)\n",
    "S_voice_istft = librosa.istft(S_voice)\n",
    "\n",
    "# Save output\n",
    "save_data(output_path, 'L_music.wav', data=L_music_istft)\n",
    "save_data(output_path, 'S_music.wav', data=S_music_istft)\n",
    "save_data(output_path, 'L_voice.wav', data=L_voice_istft)\n",
    "save_data(output_path, 'S_voice.wav', data=S_voice_istft)\n",
    "wavfile.write(output_path+filename, rate=16000, data=np.array([music, voice]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###test###\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "r = 3\n",
    "np.random.seed(123)\n",
    "base = 100 + np.cumsum(np.random.randn(n, r), axis=0)\n",
    "scales = np.abs(np.random.randn(n, r))\n",
    "L = np.dot(base, scales.T)\n",
    "S = np.round(0.25 * np.random.randn(n, n))\n",
    "M = L + S\n",
    "\n",
    "L_hat, S_hat, r, niter = pcp_alm(M,500)\n",
    "print(np.max(np.abs(S - S_hat)))\n",
    "print(np.max(np.abs(L - L_hat)))\n",
    "print(niter)\n",
    "\n",
    "\n",
    "\n",
    "_, s, _ = np.linalg.svd(L, full_matrices=False)\n",
    "print (s[s > 1e-11])\n",
    "\n",
    "_, s_hat, _ = np.linalg.svd(L_hat, full_matrices=False)\n",
    "print (s_hat[s_hat > 1e-11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "Code Reference: https://github.com/apapanico/sklearn-rpca/blob/master/sklearnrpca/rpca_alm.py \n",
    "Modified based on the alternativate direction algorithm presented in the original paper: https://statweb.stanford.edu/~candes/papers/RobustPCA.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
